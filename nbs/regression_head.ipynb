{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed7eadb3",
   "metadata": {},
   "source": [
    "## Hypothesis\n",
    "\n",
    "Our final ensemble (and all L2 models) is not predicting anything under 20. Creating a classifier able to identify samples with a Pawpularity under 20 could improve the final ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5a2c715",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml.vision.data import ImageDataModule\n",
    "from ml.learner import ImageClassifier\n",
    "from ml.params import load_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c846372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "      <th>Pawpularity</th>\n",
       "      <th>kfold</th>\n",
       "      <th>ignore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0007de18844b0dbbb5e1f607da0606e0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0009c66b9439883ba2750fb825e1d7db</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0013fd999caf9a3efe1352ca1b0d937e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0018df346ac9c1d8413cfcc888ca8246</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>001dc955e10590d3ca4673f034feeef2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1                                Id  Subject Focus  \\\n",
       "0           0             0  0007de18844b0dbbb5e1f607da0606e0              0   \n",
       "1           1             1  0009c66b9439883ba2750fb825e1d7db              0   \n",
       "2           2             2  0013fd999caf9a3efe1352ca1b0d937e              0   \n",
       "3           3             3  0018df346ac9c1d8413cfcc888ca8246              0   \n",
       "4           4             4  001dc955e10590d3ca4673f034feeef2              0   \n",
       "\n",
       "   Eyes  Face  Near  Action  Accessory  Group  Collage  Human  Occlusion  \\\n",
       "0     1     1     1       0          0      1        0      0          0   \n",
       "1     1     1     0       0          0      0        0      0          0   \n",
       "2     1     1     1       0          0      0        0      1          1   \n",
       "3     1     1     1       0          0      0        0      0          0   \n",
       "4     0     0     1       0          0      1        0      0          0   \n",
       "\n",
       "   Info  Blur  Pawpularity  kfold  ignore  \n",
       "0     0     0           63      0       0  \n",
       "1     0     0           42      2       0  \n",
       "2     0     0           28      3       0  \n",
       "3     0     0           15      3       1  \n",
       "4     0     0           72      1       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/train_folds.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cdb54c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_fpaths = [f\"../data/train/{i}.jpg\" for i in df[(df.kfold!=0)][\"Id\"]]\n",
    "train_targets = [[t / 100.] for t in df[(df.kfold!=0)].Pawpularity.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d4dc087",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_image_fpaths = [f\"../data/train/{i}.jpg\" for i in df[df.kfold==0][\"Id\"]]\n",
    "val_targets = [[t / 100.] for t in df[df.kfold==0].Pawpularity.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57d1bb55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/train/0009c66b9439883ba2750fb825e1d7db.jpg',\n",
       " '../data/train/0013fd999caf9a3efe1352ca1b0d937e.jpg',\n",
       " '../data/train/0018df346ac9c1d8413cfcc888ca8246.jpg',\n",
       " '../data/train/001dc955e10590d3ca4673f034feeef2.jpg',\n",
       " '../data/train/001dd4f6fafb890610b1635f967ea081.jpg']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_fpaths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01e56921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.42], [0.28], [0.15], [0.72], [0.74]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1952eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'two', 'seed': 7591, 'n_folds': 5, 'fold': -1, 'metric': 'auc', 'metric_mode': 'max', 'train_data': 'data/train', 'arch': 'swin_large_patch4_window7_224', 'pretrained': True, 'epochs': 6, 'bs': 64, 'auto_batch_size': False, 'accumulate_grad_batches': 1, 'precision': 'bf16', 'use_normalize': True, 'n_tfms': 1, 'magn': 5, 'sz': 224, 'use_mix': 0, 'mix_p': 0.0, 'resize': -1, 'dropout': 0.0, 'wd': 0.0, 'label_smoothing': 0.1, 'loss': 'bce_with_logits', 'opt': 'adamw', 'sched': 'cosine', 'warmup_epochs': 1, 'lr': 5e-05, 'auto_lr': False, 'mom': 0.9}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = load_cfg(\"../params.yaml\", cfg_name=\"train_two\")\n",
    "cfg.metric = 'auc'\n",
    "cfg.metric_mode = 'max'\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1d9bfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.data import transforms_factory\n",
    "\n",
    "train_aug = transforms_factory.create_transform(\n",
    "    input_size=cfg.sz,\n",
    "    is_training=True,\n",
    "    auto_augment=f\"rand-n{cfg.n_tfms}-m{cfg.magn}\",\n",
    ")\n",
    "val_aug = transforms_factory.create_transform(\n",
    "    input_size=cfg.sz,\n",
    "    is_training=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79e2cfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = ImageDataModule(\n",
    "    task=\"classification\",\n",
    "    batch_size=32,\n",
    "    # train\n",
    "    train_image_paths=train_image_fpaths,\n",
    "    train_targets=train_targets,\n",
    "    train_augmentations=val_aug,\n",
    "    # test\n",
    "    test_image_paths=val_image_fpaths,\n",
    "    test_augmentations=val_aug,\n",
    ")\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e698b499",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:2156.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "/opt/conda/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = ImageClassifier(\n",
    "    in_channels=3,\n",
    "    num_classes=1,\n",
    "    pretrained=cfg.pretrained,\n",
    "    cfg=cfg,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a71719a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input_1', '0', '1', '2', '3']\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "\n",
    "\n",
    "nodes, _ = get_graph_node_names(model.head)\n",
    "print(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab9f3510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): LazyLinear(in_features=0, out_features=128, bias=True)\n",
       "  (1): Dropout(p=0.1, inplace=False)\n",
       "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (3): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7129a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_extractor = create_feature_extractor(\n",
    "#     model.head, return_nodes=['2'])\n",
    "\n",
    "import torch\n",
    "\n",
    "# input = torch.randn(2, 3, 224, 224)\n",
    "# x = model.backbone(input)\n",
    "# out = feature_extractor(x)\n",
    "# out['2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d3ebc0d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../ckpts/model_two_fold0.ckpt',\n",
       " '../ckpts/model_two_fold1.ckpt',\n",
       " '../ckpts/model_two_fold2.ckpt',\n",
       " '../ckpts/model_two_fold3.ckpt',\n",
       " '../ckpts/model_two_fold4.ckpt']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_fpaths = [\n",
    "    f\"../ckpts/model_{cfg.name}_fold{i}.ckpt\"\n",
    "    for i in range(cfg.n_folds)\n",
    "]\n",
    "ckpt_fpaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "03f3b576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Generating predictions using model {cfg.name}...\")\n",
    "# for idx, ckpt_fpath in enumerate(ckpt_fpaths[:2]):\n",
    "ckpt = torch.load(ckpt_fpaths[0])\n",
    "model.load_state_dict(ckpt[\"state_dict\"])\n",
    "\n",
    "model.backbone.to('cuda')\n",
    "model.backbone.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2c7f20dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.head.to('cuda')\n",
    "model.head.eval()\n",
    "feature_extractor = create_feature_extractor(\n",
    "    model.head, return_nodes=['1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7f3c4f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emb = []\n",
    "tar = []\n",
    "for batch in dm.train_dataloader():\n",
    "    out = feature_extractor(model.backbone(batch[0].to('cuda')))['1'].detach().cpu().numpy()\n",
    "    train_emb.extend(out) \n",
    "    tar.extend(batch[1].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "75125b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7872, 128)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_emb = np.vstack(train_emb)\n",
    "train_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fe80f58d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7872, 1)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar = np.vstack(tar)\n",
    "tar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0f5617ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "238dd17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/model_selection/_split.py:443: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  fold_sizes = np.full(n_splits, n_samples // n_splits, dtype=np.int)\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/model_selection/_split.py:93: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/model_selection/_split.py:93: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/model_selection/_split.py:93: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/model_selection/_split.py:93: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/model_selection/_split.py:93: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LassoCV()"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LassoCV()\n",
    "reg.fit(X=train_emb, y=tar.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "64da41b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_emb = []\n",
    "for batch in dm.test_dataloader():\n",
    "    out = feature_extractor(model.backbone(batch.to('cuda')))['1'].detach().cpu().numpy()\n",
    "    test_emb.extend(out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b92c7431",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = np.clip(reg.predict(X=test_emb), a_min=0, a_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "82f0baa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11538547, 0.3834828, 1.0)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.min(), y_hat.mean(), y_hat.max(), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f913b253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1724056672829159"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(val_targets, y_hat, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "18e070a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.24"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "17.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a4e1b47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(y_hat, bins=50);\n",
    "plt.hist(np.array(val_targets), bins=50, alpha=.25);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506db21c",
   "metadata": {},
   "source": [
    "## nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "738100e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "/opt/conda/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5e846c217c445c814ec15003828727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dm = ImageDataModule(\n",
    "    task=\"classification\",\n",
    "    batch_size=32,\n",
    "    # test\n",
    "    test_image_paths=train_image_fpaths,\n",
    "    test_augmentations=val_aug,\n",
    ")\n",
    "dm.setup()\n",
    "\n",
    "ckpt = torch.load(ckpt_fpaths[0])\n",
    "model = ImageClassifier(\n",
    "    in_channels=3,\n",
    "    num_classes=1,\n",
    "    pretrained=cfg.pretrained,\n",
    "    cfg=cfg,\n",
    ")\n",
    "model.load_state_dict(ckpt[\"state_dict\"])\n",
    "from torch import nn\n",
    "model.head = nn.Identity()\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "trainer = pl.Trainer(gpus=1)\n",
    "preds = trainer.predict(model, dm.test_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "56d9463b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR()"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_emb = np.vstack(preds)\n",
    "reg = SVR()\n",
    "reg.fit(X=train_emb, y=train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "244da07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "/opt/conda/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e01c47672154f059ebb8be542123ecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dm = ImageDataModule(\n",
    "    task=\"classification\",\n",
    "    batch_size=32,\n",
    "    # test\n",
    "    test_image_paths=val_image_fpaths,\n",
    "    test_augmentations=val_aug,\n",
    ")\n",
    "dm.setup()\n",
    "\n",
    "ckpt = torch.load(ckpt_fpaths[0])\n",
    "model = ImageClassifier(\n",
    "    in_channels=3,\n",
    "    num_classes=1,\n",
    "    pretrained=cfg.pretrained,\n",
    "    cfg=cfg,\n",
    ")\n",
    "model.load_state_dict(ckpt[\"state_dict\"])\n",
    "from torch import nn\n",
    "model.head = nn.Identity()\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "trainer = pl.Trainer(gpus=1)\n",
    "preds = trainer.predict(model, dm.test_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "51960c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_emb = np.vstack(preds)\n",
    "y_hat = np.clip(reg.predict(X=test_emb), a_min=0, a_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b0edbfbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07818510943675377, 0.39200319615122403, 1.0)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.min(), y_hat.mean(), y_hat.max(), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "896cbc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17914925780404223"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(val_targets, y_hat, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "23a61bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(y_hat, bins=50);\n",
    "plt.hist(np.array(val_targets), bins=50, alpha=.25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ed9af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fbe949",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
