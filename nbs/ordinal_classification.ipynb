{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdef7777",
   "metadata": {},
   "source": [
    "## Hypothesis\n",
    "\n",
    "Predicting the exact score is hard. We could reduce the complexity by interpreting this challenge as an **ordinal classification** problem. The key point here is that the probability of `class_1` is lower than `class_0`. Multi-class or multi-label problems do not have this critical ingridient.\n",
    "\n",
    "To start, we could reduce the number of classes from 100 to 10, and encode them in a way that let the model understand that the the probability of Pawpularity been higher than 20, is strictly lower than higher than 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "650070e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f652732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml.vision.data import ImageDataModule\n",
    "from ml.learner import ImageClassifier\n",
    "from ml.params import load_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9419caa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "      <th>Pawpularity</th>\n",
       "      <th>kfold</th>\n",
       "      <th>ignore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0007de18844b0dbbb5e1f607da0606e0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0009c66b9439883ba2750fb825e1d7db</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0013fd999caf9a3efe1352ca1b0d937e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0018df346ac9c1d8413cfcc888ca8246</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>001dc955e10590d3ca4673f034feeef2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1                                Id  Subject Focus  \\\n",
       "0           0             0  0007de18844b0dbbb5e1f607da0606e0              0   \n",
       "1           1             1  0009c66b9439883ba2750fb825e1d7db              0   \n",
       "2           2             2  0013fd999caf9a3efe1352ca1b0d937e              0   \n",
       "3           3             3  0018df346ac9c1d8413cfcc888ca8246              0   \n",
       "4           4             4  001dc955e10590d3ca4673f034feeef2              0   \n",
       "\n",
       "   Eyes  Face  Near  Action  Accessory  Group  Collage  Human  Occlusion  \\\n",
       "0     1     1     1       0          0      1        0      0          0   \n",
       "1     1     1     0       0          0      0        0      0          0   \n",
       "2     1     1     1       0          0      0        0      1          1   \n",
       "3     1     1     1       0          0      0        0      0          0   \n",
       "4     0     0     1       0          0      1        0      0          0   \n",
       "\n",
       "   Info  Blur  Pawpularity  kfold  ignore  \n",
       "0     0     0           63      0       0  \n",
       "1     0     0           42      2       0  \n",
       "2     0     0           28      3       0  \n",
       "3     0     0           15      3       1  \n",
       "4     0     0           72      1       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/train_folds.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7530ed59",
   "metadata": {},
   "source": [
    "One way to encode the ordinal information is:\n",
    "\n",
    "* `class_0`: `[0, 0, 0, 0, 0, 0, 0, 0, 0]`,\n",
    "* `class_1`: `[1, 0, 0, 0, 0, 0, 0, 0, 0]`,\n",
    "* `class_2`: `[1, 1, 0, 0, 0, 0, 0, 0, 0]`,\n",
    "* ...\n",
    "\n",
    "Due to this encoding scheme, the model will learn that having the first 8 elements equal to 1 is less likely than having just the first 2 elements equal to 1.\n",
    "\n",
    "At prediction/inference time, we can then postprocess the predictions to match the range of the original target variable â€• e.g., `class_0` -> `5`, `class_9` -> `95`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8955e4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls2enc = {\n",
    "    0: [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    1: [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    2: [1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "    3: [1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
    "    4: [1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
    "    5: [1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
    "    6: [1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
    "    7: [1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
    "    8: [1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
    "    9: [1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "}\n",
    "\n",
    "# NOTE: lists are not hashable objects, so cannot be used as keys in\n",
    "# a dictionary. One trick is to convert the list to a set, as these \n",
    "# are immutable and hashable\n",
    "enc2cls = {tuple(v): k for k, v in cls2enc.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4aba5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0, 0, 0, 0, 0, 0, 0, 0): 0,\n",
       " (1, 0, 0, 0, 0, 0, 0, 0, 0): 1,\n",
       " (1, 1, 0, 0, 0, 0, 0, 0, 0): 2,\n",
       " (1, 1, 1, 0, 0, 0, 0, 0, 0): 3,\n",
       " (1, 1, 1, 1, 0, 0, 0, 0, 0): 4,\n",
       " (1, 1, 1, 1, 1, 0, 0, 0, 0): 5,\n",
       " (1, 1, 1, 1, 1, 1, 0, 0, 0): 6,\n",
       " (1, 1, 1, 1, 1, 1, 1, 0, 0): 7,\n",
       " (1, 1, 1, 1, 1, 1, 1, 1, 0): 8,\n",
       " (1, 1, 1, 1, 1, 1, 1, 1, 1): 9}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc2cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18666133",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_fpaths = [f\"../data/train/{i}.jpg\" for i in df[df.kfold!=0][\"Id\"]]\n",
    "train_targets = [cls2enc[t] for t in pd.cut(df[df.kfold!=0].Pawpularity.tolist(), bins=10, retbins=True, labels=False)[0].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1e10ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original target: [42, 28, 15, 72, 74]\n",
      "New target: [[1, 1, 1, 1, 0, 0, 0, 0, 0], [1, 1, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original target: {df[df.kfold!=0].Pawpularity.tolist()[:5]}\")\n",
    "print(f\"New target: {train_targets[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86cbd453",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_image_fpaths = [f\"../data/train/{i}.jpg\" for i in df[df.kfold==0][\"Id\"]]\n",
    "val_targets = [cls2enc[t] for t in pd.cut(df[df.kfold==0].Pawpularity.tolist(), bins=10, retbins=True, labels=False)[0].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c6487b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 0, 0, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_targets[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7d98e4",
   "metadata": {},
   "source": [
    "## Model training \n",
    "\n",
    "Let's use a Swin transformer architecture as backbone for our model, and use a head with 9 output nodes to match the size of our targets.\n",
    "\n",
    "We will use AUROC to monitor the performance of the model as if this was a multi-label classification model. After having fitted the model, we will reproces the model's predictions to match the original scale of the target variable. Hopefully, RMSE should be not too far â€• or better â€• than what we were able to achieve by threating the problem as a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "deee1edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'two', 'seed': 7591, 'n_folds': 5, 'fold': -1, 'metric': 'auc', 'metric_mode': 'max', 'train_data': 'data/train', 'arch': 'swin_large_patch4_window7_224', 'pretrained': True, 'epochs': 6, 'bs': 64, 'auto_batch_size': False, 'accumulate_grad_batches': 1, 'precision': 'bf16', 'use_normalize': True, 'n_tfms': 1, 'magn': 5, 'sz': 224, 'use_mix': 0, 'mix_p': 0.0, 'resize': -1, 'dropout': 0.0, 'wd': 0.0, 'label_smoothing': 0.1, 'loss': 'bce_with_logits', 'opt': 'adamw', 'sched': 'cosine', 'warmup_epochs': 1, 'lr': 5e-05, 'auto_lr': False, 'mom': 0.9, 'num_classes': 9}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = load_cfg(\"../params.yaml\", cfg_name=\"train_two\")\n",
    "cfg.metric = 'auc'\n",
    "cfg.metric_mode = 'max'\n",
    "cfg.num_classes = 9\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34ed0cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.data import transforms_factory\n",
    "\n",
    "train_aug = transforms_factory.create_transform(\n",
    "    input_size=cfg.sz,\n",
    "    is_training=True,\n",
    "    auto_augment=f\"rand-n{cfg.n_tfms}-m{cfg.magn}\",\n",
    ")\n",
    "val_aug = transforms_factory.create_transform(\n",
    "    input_size=cfg.sz,\n",
    "    is_training=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a623e620",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = ImageDataModule(\n",
    "    task=\"classification\",\n",
    "    batch_size=cfg.bs,\n",
    "    # train\n",
    "    train_image_paths=train_image_fpaths,\n",
    "    train_targets=train_targets,\n",
    "    train_augmentations=train_aug,\n",
    "    # valid\n",
    "    val_image_paths=val_image_fpaths,\n",
    "    val_targets=val_targets,\n",
    "    val_augmentations=val_aug,\n",
    "    # test\n",
    "    test_image_paths=val_image_fpaths,\n",
    "    test_augmentations=val_aug,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21f9b4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:2156.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "/opt/conda/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = ImageClassifier(\n",
    "    in_channels=3,\n",
    "    num_classes=10,  # NOTE: 10 classes. All 0s is a class in itself\n",
    "    pretrained=cfg.pretrained,\n",
    "    cfg=cfg,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "917f5e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): LazyLinear(in_features=0, out_features=128, bias=True)\n",
       "  (1): Dropout(p=0.1, inplace=False)\n",
       "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (3): Linear(in_features=64, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "model.head = nn.Sequential(\n",
    "    nn.LazyLinear(128),\n",
    "    nn.Dropout(p=0.1),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.Linear(64, 9),  # NOTE: 9 nodes output\n",
    ")\n",
    "model.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c898f37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl \n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    precision=cfg.precision,\n",
    "    auto_lr_find=cfg.auto_lr,\n",
    "    accumulate_grad_batches=cfg.accumulate_grad_batches,\n",
    "    auto_scale_batch_size=cfg.auto_batch_size,\n",
    "    max_epochs=cfg.epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9cdfabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainerFn.FITTING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/utilities/model_summary.py:431: UserWarning: A layer with UninitializedParameter was found. Thus, the total number of parameters detected may be inaccurate.\n",
      "  warning_cache.warn(\n",
      "\n",
      "  | Name         | Type            | Params\n",
      "-------------------------------------------------\n",
      "0 | backbone     | SwinTransformer | 194 M \n",
      "1 | head         | Sequential      | 8.8 K \n",
      "2 | train_metric | AUROC           | 0     \n",
      "3 | val_metric   | AUROC           | 0     \n",
      "-------------------------------------------------\n",
      "195 M     Trainable params\n",
      "0         Non-trainable params\n",
      "195 M     Total params\n",
      "780.017   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1fdc34eefd454aba6169a89d89a613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec67b98b7b34475fb8247af49f49bf10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18cfe578c2d34e9aabcb9a00145ff3a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da729eef8d84291bf81a490006d22aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 // train metric: 0.5399, valid metric: 0.7390\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7cfb81223544340b7995d140f2ee54f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 // train metric: 0.6233, valid metric: 0.7430\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73704798b4e442287fb71bf12458b5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 // train metric: 0.6670, valid metric: 0.7525\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9923d815556045209d999912cdb6abe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 // train metric: 0.6962, valid metric: 0.7590\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d1db5fabf994caf9abb1a1eaedfabb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 // train metric: 0.7181, valid metric: 0.7633\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0260e10f",
   "metadata": {},
   "source": [
    "The model seems to be pretty decent. Let's see how this translates to the competition metric (RMSE) after postprocessing the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eed9489d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /workspace/nbs/lightning_logs/version_122/checkpoints/epoch=5-step=737.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from checkpoint at /workspace/nbs/lightning_logs/version_122/checkpoints/epoch=5-step=737.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc03f0c2ffe464f8507a9e2815557f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 123it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "outs = trainer.predict(model, dm.test_dataloader(), ckpt_path=\"best\")\n",
    "outs = np.vstack(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3af053b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45, 25, 75, ..., 35, 25, 45])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = ((outs > 0.5).sum(1) * 10) + 5\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8265eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([63, 22, 53, ..., 34, 35, 20])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = df[df.kfold==0].Pawpularity.values\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d958586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.761599882323292"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "metric = mean_squared_error(y_pred, y_true, squared=False)\n",
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed160da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 95)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.min(), y_pred.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91aa0370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAATU0lEQVR4nO3dbaxd1X3n8e8vOJCEzmAe7ljUNmOPYiVClSD0KnWUTtXBzYiHKuYFQURVsZBnPC9IS5pKjTvzIqo0LxypKg2aEZInTmuqDAmlyWAlKC01RO28gMZOGMJDMtwQiG0ZfEvB6QRlEib/eXGWy7Gxfc/1Pfdp3e9HOjprrb32OWt7+/7uvuvss3eqCklSX9622AOQJI2f4S5JHTLcJalDhrskdchwl6QOrVrsAQBcdtlltWHDhsUehiQtKwcPHvz7qpo43bIlEe4bNmzgwIEDiz0MSVpWkrx4pmVOy0hShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUoeWxDdUNX827PzqSfUXdt24SCORtJA8cpekDhnuktQhw12SOmS4S1KHRgr3JL+T5OkkTyW5L8k7kmxM8niSqSRfTHJ+63tBq0+15RvmdQskSW8xY7gnWQv8NjBZVb8AnAfcCnwauKuq3g28Cmxvq2wHXm3td7V+kqQFNOq0zCrgnUlWAe8CjgLXAg+05XuBm1p5a6vTlm9JkrGMVpI0khnDvaqOAH8I/IBBqB8HDgKvVdUbrdthYG0rrwUOtXXfaP0vPfV1k+xIciDJgenp6bluhyRpyCjTMhczOBrfCPw8cCFw3VzfuKp2V9VkVU1OTJz2FoCSpHM0yrTMrwHfr6rpqvop8CXgg8DqNk0DsA440spHgPUAbflFwCtjHbUk6axGCfcfAJuTvKvNnW8BngEeBW5ufbYBD7byvlanLX+kqmp8Q5YkzWSUOffHGXww+k3g222d3cAngU8kmWIwp76nrbIHuLS1fwLYOQ/jliSdxUgXDquqTwGfOqX5eeD9p+n7Y+Ajcx+aJOlc+Q1VSeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHRrlB9nuSPDH0+GGSjye5JMnDSZ5rzxe3/klyd5KpJE8muWb+N0OSNGyU2+x9t6qurqqrgV8EXge+zOD2efurahOwnzdvp3c9sKk9dgD3zMO4JUlnMdtpmS3A96rqRWArsLe17wVuauWtwL018BiwOsnl4xisJGk0sw33W4H7WnlNVR1t5ZeANa28Fjg0tM7h1naSJDuSHEhyYHp6epbDkCSdzcjhnuR84MPAn5+6rKoKqNm8cVXtrqrJqpqcmJiYzaqSpBnM5sj9euCbVfVyq798YrqlPR9r7UeA9UPrrWttkqQFMptw/yhvTskA7AO2tfI24MGh9tvaWTObgeND0zeSpAWwapROSS4EPgT8h6HmXcD9SbYDLwK3tPaHgBuAKQZn1tw+ttFKkkYyUrhX1Y+AS09pe4XB2TOn9i3gjrGMTpJ0TvyGqiR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQyOFe5LVSR5I8p0kzyb5QJJLkjyc5Ln2fHHrmyR3J5lK8mSSa+Z3EyRJpxr1yP0zwNeq6r3AVcCzwE5gf1VtAva3OgxupL2pPXYA94x1xJKkGc0Y7kkuAn4F2ANQVT+pqteArcDe1m0vcFMrbwXurYHHgNVJLh/zuCVJZzHKPVQ3AtPAnyS5CjgI3Amsqaqjrc9LwJpWXgscGlr/cGs7OtRGkh0Mjuy54oorznX8WqI27PzqW9pe2HXjIoxEWplGmZZZBVwD3FNV7wN+xJtTMMA/3RS7ZvPGVbW7qiaranJiYmI2q0qSZjBKuB8GDlfV463+AIOwf/nEdEt7PtaWHwHWD62/rrVJkhbIjOFeVS8Bh5K8pzVtAZ4B9gHbWts24MFW3gfc1s6a2QwcH5q+kSQtgFHm3AF+C/h8kvOB54HbGfxiuD/JduBF4JbW9yHgBmAKeL31lSQtoJHCvaqeACZPs2jLafoWcMfchiVJmgu/oSpJHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6tBI4Z7khSTfTvJEkgOt7ZIkDyd5rj1f3NqT5O4kU0meTHLNfG6AJOmtZnPk/m+q6uqqOnFHpp3A/qraBOxvdYDrgU3tsQO4Z1yDlSSNZi7TMluBva28F7hpqP3eGngMWJ3k8jm8jyRplkYN9wL+KsnBJDta25qqOtrKLwFrWnktcGho3cOt7SRJdiQ5kOTA9PT0OQxdknQmI90gG/jlqjqS5F8ADyf5zvDCqqokNZs3rqrdwG6AycnJWa0rSTq7kY7cq+pIez4GfBl4P/DyiemW9nysdT8CrB9afV1rkyQtkBnDPcmFSf7ZiTLwb4GngH3AttZtG/BgK+8DbmtnzWwGjg9N30iSFsAo0zJrgC8nOdH/v1fV15J8A7g/yXbgReCW1v8h4AZgCngduH3so5YkndWM4V5VzwNXnab9FWDLadoLuGMso5MknRO/oSpJHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHRg73JOcl+VaSr7T6xiSPJ5lK8sUk57f2C1p9qi3fME9jlySdwWyO3O8Enh2qfxq4q6reDbwKbG/t24FXW/tdrZ8kaQGNFO5J1gE3Ap9t9QDXAg+0LnuBm1p5a6vTlm9p/SVJC2TUI/c/Bn4P+FmrXwq8VlVvtPphYG0rrwUOAbTlx1t/SdICmTHck/w6cKyqDo7zjZPsSHIgyYHp6elxvrQkrXijHLl/EPhwkheALzCYjvkMsDrJiRtsrwOOtPIRYD1AW34R8MqpL1pVu6tqsqomJyYm5rQRkqSTzRjuVfX7VbWuqjYAtwKPVNVvAI8CN7du24AHW3lfq9OWP1JVNdZRS5LOai7nuX8S+ESSKQZz6nta+x7g0tb+CWDn3IYoSZqtVTN3eVNVfR34eis/D7z/NH1+DHxkDGOTJJ0jv6EqSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SerQKDfIfkeSv0vyv5I8neQPWvvGJI8nmUryxSTnt/YLWn2qLd8wz9sgSTrFKEfu/xe4tqquAq4GrkuyGfg0cFdVvRt4Fdje+m8HXm3td7V+kqQFNMoNsquq/k+rvr09CrgWeKC17wVuauWtrU5bviVJxjVgSdLMRppzT3JekieAY8DDwPeA16rqjdblMLC2ldcChwDa8uMMbqB96mvuSHIgyYHp6ek5bYQk6WQjhXtV/b+quhpYx+Cm2O+d6xtX1e6qmqyqyYmJibm+nCRpyKzOlqmq14BHgQ8Aq5OsaovWAUda+QiwHqAtvwh4ZRyDlSSNZpSzZSaSrG7ldwIfAp5lEPI3t27bgAdbeV+r05Y/UlU1xjFLkmawauYuXA7sTXIeg18G91fVV5I8A3whyX8GvgXsaf33AH+WZAr4B+DWeRi3JOksZgz3qnoSeN9p2p9nMP9+avuPgY+MZXSSpHPiN1QlqUOjTMtIy8qGnV89qf7CrhsXaSTS4vHIXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1aJTb7K1P8miSZ5I8neTO1n5JkoeTPNeeL27tSXJ3kqkkTya5Zr43QpJ0slGO3N8AfreqrgQ2A3ckuRLYCeyvqk3A/lYHuB7Y1B47gHvGPmpJ0lnNGO5VdbSqvtnK/8jg5thrga3A3tZtL3BTK28F7q2Bx4DVSS4f98AlSWc2qzn3JBsY3E/1cWBNVR1ti14C1rTyWuDQ0GqHW9upr7UjyYEkB6anp2c7bknSWYwc7kl+DvgL4ONV9cPhZVVVQM3mjatqd1VNVtXkxMTEbFaVJM1gpHBP8nYGwf75qvpSa375xHRLez7W2o8A64dWX9faJEkLZJSzZQLsAZ6tqj8aWrQP2NbK24AHh9pva2fNbAaOD03fSJIWwKoR+nwQ+E3g20meaG3/EdgF3J9kO/AicEtb9hBwAzAFvA7cPs4BS5JmNmO4V9X/BHKGxVtO07+AO+Y4LknSHPgNVUnqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6tAolx/QSvT9vz19+8Z/vbDjkHROPHKXpA4Z7pLUIcNdkjrknLs0Jht2fvWk+gu7blykkUiGe19O8yHo5rc9w2M/u3Lk/pL64LSMJHVolNvsfS7JsSRPDbVdkuThJM+154tbe5LcnWQqyZNJrpnPwUuSTm+UaZk/Bf4LcO9Q205gf1XtSrKz1T8JXA9sao9fAu5pz1pEm9/2zJuV7//zxRuIpAUzym32/ibJhlOatwK/2sp7ga8zCPetwL3tVnuPJVmd5HJvkL1ynfEXi1+GkubVuX6gumYosF8C1rTyWuDQUL/Dre0t4Z5kB7AD4IorrjjHYaxQfhAqaQZz/kC1HaXXOay3u6omq2pyYmJirsOQJA051yP3l09MtyS5HDjW2o8A64f6rWtt6oXXnJGWhXMN933ANmBXe35wqP1jSb7A4IPU4863rxCnhP5Jc+2SFtyM4Z7kPgYfnl6W5DDwKQahfn+S7cCLwC2t+0PADcAU8Dpw+zyMWZI0g1HOlvnoGRZtOU3fAu6Y66AkSXPj5Qe0OJy7l+aV4b6UrcRTHg19aSwM96VgJYb4bBn60qx44TBJ6pBH7pLOmdewX7oMdy1vs72GvbRYFnhq0XCXlrlTj57BI2gZ7lpp/GBWK4QfqEpShzxyV5e8QYlWOo/cJalDy//IfTnNofplpeVnFvvsxF8Lnqkz//wQeWbLP9wXk2Gt0/inKaG5TgctxQMULRuGuwRL8xf1cvqrVEuO4T6KpfiDr5XrDDdGcTpIw/oNd496tMKM7QyhM/2MnOHbwOAvlqVoXsI9yXXAZ4DzgM9W1a75eJ+x8whdOqefAz9nWHrGHu5JzgP+K/Ah4DDwjST7qmpp3FTTAJeWrhF/Pmf8i2G2f7mPKxeW0C+n+Thyfz8wVVXPA7SbZW8Flka4S+rGrKeixhDit/63x06qf+Hfbx7r649LBrc9HeMLJjcD11XVv2v13wR+qao+dkq/HcCOVn0P8N0ZXvoy4O/HOtjlwe1eWVbqdsPK3fa5bPe/rKqJ0y1YtA9Uq2o3sHvU/kkOVNXkPA5pSXK7V5aVut2wcrd9vrZ7Pi4/cARYP1Rf19okSQtkPsL9G8CmJBuTnA/cCuybh/eRJJ3B2KdlquqNJB8D/pLBqZCfq6qnx/DSI0/hdMbtXllW6nbDyt32ednusX+gKklafF7yV5I6ZLhLUoeWRbgnuS7Jd5NMJdm52OOZL0nWJ3k0yTNJnk5yZ2u/JMnDSZ5rzxcv9ljHLcl5Sb6V5CutvjHJ422ff7F9ON+dJKuTPJDkO0meTfKBFbK/f6f9H38qyX1J3tHjPk/yuSTHkjw11Hba/ZuBu9v2P5nkmrm895IP96HLGVwPXAl8NEmvVyl6A/jdqroS2Azc0bZ1J7C/qjYB+1u9N3cCzw7VPw3cVVXvBl4Fti/KqObfZ4CvVdV7gasY/Bt0vb+TrAV+G5isql9gcOLFrfS5z/8UuO6UtjPt3+uBTe2xA7hnLm+85MOdocsZVNVPgBOXM+hOVR2tqm+28j8y+EFfy2B797Zue4GbFmWA8yTJOuBG4LOtHuBa4IHWpbttBkhyEfArwB6AqvpJVb1G5/u7WQW8M8kq4F3AUTrc51X1N8A/nNJ8pv27Fbi3Bh4DVie5/FzfezmE+1rg0FD9cGvrWpINwPuAx4E1VXW0LXoJWLNY45onfwz8HvCzVr8UeK2q3mj1Xvf5RmAa+JM2JfXZJBfS+f6uqiPAHwI/YBDqx4GDrIx9Dmfev2PNuuUQ7itOkp8D/gL4eFX9cHhZDc5d7eb81SS/DhyrqoOLPZZFsAq4Brinqt4H/IhTpmB6298AbY55K4Nfbj8PXMhbpy5WhPncv8sh3FfU5QySvJ1BsH++qr7Uml8+8edZez62WOObBx8EPpzkBQZTbtcymIde3f5kh373+WHgcFU93uoPMAj7nvc3wK8B36+q6ar6KfAlBv8PVsI+hzPv37Fm3XII9xVzOYM217wHeLaq/mho0T5gWytvAx5c6LHNl6r6/apaV1UbGOzbR6rqN4BHgZtbt662+YSqegk4lOQ9rWkLg0tjd7u/mx8Am5O8q/2fP7Hd3e/z5kz7dx9wWztrZjNwfGj6Zvaqask/gBuA/w18D/hPiz2eedzOX2bwJ9qTwBPtcQODOej9wHPAXwOXLPZY52n7fxX4Siv/K+DvgCngz4ELFnt887TNVwMH2j7/H8DFK2F/A38AfAd4Cvgz4IIe9zlwH4PPFX7K4C+17Wfav0AYnBn4PeDbDM4mOuf39vIDktSh5TAtI0maJcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdej/A6RXRACyHu9wAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(y_pred, bins=50);\n",
    "plt.hist(y_true, bins=50, alpha=.25);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e8822a",
   "metadata": {},
   "source": [
    "Despite the good RMSE, the model is currently over-estimating the number of samples with Pawpularity between 20-40."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3caa2cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): LazyLinear(in_features=0, out_features=128, bias=True)\n",
       "  (1): Dropout(p=0.1, inplace=False)\n",
       "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ImageClassifier(\n",
    "    in_channels=3,\n",
    "    num_classes=10,  # NOTE: 10 classes. All 0s is a class in itself\n",
    "    pretrained=cfg.pretrained,\n",
    "    cfg=cfg,\n",
    ")\n",
    "model.head = nn.Sequential(\n",
    "    nn.LazyLinear(128),\n",
    "    nn.Dropout(p=0.1),\n",
    "    nn.Linear(128, 64),\n",
    ")\n",
    "model.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b7cbdf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(64, 1, bias=False)\n",
    "model.linear_1_bias = nn.Parameter(torch.zeros(9).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2384eaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# credit: https://stackoverflow.com/a/28127947\n",
    "def new_forward(self, x):\n",
    "    x = self.backbone(x)\n",
    "    x = self.head(x)\n",
    "    \n",
    "    logits = self.fc(x) + self.linear_1_bias\n",
    "    return logits\n",
    "    \n",
    "model.forward = new_forward.__get__(model, ImageClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5663282e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name         | Type            | Params\n",
      "-------------------------------------------------\n",
      "0 | backbone     | SwinTransformer | 194 M \n",
      "1 | head         | Sequential      | 8.3 K \n",
      "2 | train_metric | AUROC           | 0     \n",
      "3 | val_metric   | AUROC           | 0     \n",
      "4 | fc           | Linear          | 64    \n",
      "-------------------------------------------------\n",
      "195 M     Trainable params\n",
      "0         Non-trainable params\n",
      "195 M     Total params\n",
      "780.015   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2965a7190ac34d05878722dc84d881ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2017e4215bb471d9caa9bd3d555a612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcfe9bb7347d4781998344db0247b1fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8311263b00d14c22ab480e51d4bc4b16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 // train metric: 0.6192, valid metric: 0.7600\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5d6457001444d08d25bd1a7acb146f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 // train metric: 0.6819, valid metric: 0.7669\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "923ad600610d4233b091c3f30e9371b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 // train metric: 0.7112, valid metric: 0.7708\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb024bf9da174f9da73ad2288e9b8a0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 // train metric: 0.7320, valid metric: 0.7737\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "402d4b11fb3e4ce28cf595dcf9787187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 // train metric: 0.7502, valid metric: 0.7759\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    precision=cfg.precision,\n",
    "    auto_lr_find=cfg.auto_lr,\n",
    "    accumulate_grad_batches=cfg.accumulate_grad_batches,\n",
    "    auto_scale_batch_size=cfg.auto_batch_size,\n",
    "    max_epochs=cfg.epochs,\n",
    ")\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d205af",
   "metadata": {},
   "source": [
    "This is already a big improvement in AUROC! Let's see if it translates to a better RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "64c165a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /workspace/nbs/lightning_logs/version_129/checkpoints/epoch=5-step=737.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from checkpoint at /workspace/nbs/lightning_logs/version_129/checkpoints/epoch=5-step=737.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7f76e5a58b44e09a6f00cd1186af3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 123it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "outs = trainer.predict(model, dm.test_dataloader(), ckpt_path=\"best\")\n",
    "outs = np.vstack(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "50e34ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  5, 95, ...,  5,  5,  5])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = ((outs > 0.5).sum(1) * 10) + 5\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a2edd2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([63, 22, 53, ..., 34, 35, 20])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = df[df.kfold==0].Pawpularity.values\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "314e7878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.45424578670089"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "metric = mean_squared_error(y_pred, y_true, squared=False)\n",
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7f66876a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 95)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.min(), y_pred.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8ca22d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(y_pred, bins=50);\n",
    "plt.hist(y_true, bins=50, alpha=.25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25550e00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
