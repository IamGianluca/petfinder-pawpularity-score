{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f76c67c",
   "metadata": {},
   "source": [
    "## Hypothesis\n",
    "\n",
    "Our final ensemble (and all L2 models) is not predicting anything under 20. Creating a classifier able to identify samples with a Pawpularity under 20 could improve the final ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e797816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml.vision.data import ImageDataModule\n",
    "from ml.learner import ImageClassifier\n",
    "from ml.params import load_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff4f4474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "      <th>Pawpularity</th>\n",
       "      <th>kfold</th>\n",
       "      <th>ignore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0007de18844b0dbbb5e1f607da0606e0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0009c66b9439883ba2750fb825e1d7db</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0013fd999caf9a3efe1352ca1b0d937e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0018df346ac9c1d8413cfcc888ca8246</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>001dc955e10590d3ca4673f034feeef2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1                                Id  Subject Focus  \\\n",
       "0           0             0  0007de18844b0dbbb5e1f607da0606e0              0   \n",
       "1           1             1  0009c66b9439883ba2750fb825e1d7db              0   \n",
       "2           2             2  0013fd999caf9a3efe1352ca1b0d937e              0   \n",
       "3           3             3  0018df346ac9c1d8413cfcc888ca8246              0   \n",
       "4           4             4  001dc955e10590d3ca4673f034feeef2              0   \n",
       "\n",
       "   Eyes  Face  Near  Action  Accessory  Group  Collage  Human  Occlusion  \\\n",
       "0     1     1     1       0          0      1        0      0          0   \n",
       "1     1     1     0       0          0      0        0      0          0   \n",
       "2     1     1     1       0          0      0        0      1          1   \n",
       "3     1     1     1       0          0      0        0      0          0   \n",
       "4     0     0     1       0          0      1        0      0          0   \n",
       "\n",
       "   Info  Blur  Pawpularity  kfold  ignore  \n",
       "0     0     0           63      0       0  \n",
       "1     0     0           42      2       0  \n",
       "2     0     0           28      3       0  \n",
       "3     0     0           15      3       1  \n",
       "4     0     0           72      1       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/train_folds.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "548ed157",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_fpaths = [f\"../data/train/{i}.jpg\" for i in df[df.kfold!=0][\"Id\"]]\n",
    "train_targets = [[1] if t <= 20 else [0] for t in df[df.kfold!=0].Pawpularity.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "923623ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_image_fpaths = [f\"../data/train/{i}.jpg\" for i in df[df.kfold==0][\"Id\"]]\n",
    "val_targets = [[1] if t <= 20 else [0] for t in df[df.kfold==0].Pawpularity.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e315f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/train/0009c66b9439883ba2750fb825e1d7db.jpg',\n",
       " '../data/train/0013fd999caf9a3efe1352ca1b0d937e.jpg',\n",
       " '../data/train/0018df346ac9c1d8413cfcc888ca8246.jpg',\n",
       " '../data/train/001dc955e10590d3ca4673f034feeef2.jpg',\n",
       " '../data/train/001dd4f6fafb890610b1635f967ea081.jpg']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_fpaths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d5a0940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [0], [1], [0], [0]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8ae7c503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'two', 'seed': 7591, 'n_folds': 5, 'fold': -1, 'metric': 'auc', 'metric_mode': 'max', 'train_data': 'data/train', 'arch': 'swin_large_patch4_window7_224', 'pretrained': True, 'epochs': 6, 'bs': 64, 'auto_batch_size': False, 'accumulate_grad_batches': 1, 'precision': 'bf16', 'use_normalize': True, 'n_tfms': 1, 'magn': 5, 'sz': 224, 'use_mix': 0, 'mix_p': 0.0, 'resize': -1, 'dropout': 0.0, 'wd': 0.0, 'label_smoothing': 0.1, 'loss': 'bce_with_logits', 'opt': 'adamw', 'sched': 'cosine', 'warmup_epochs': 1, 'lr': 5e-05, 'auto_lr': False, 'mom': 0.9}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = load_cfg(\"../params.yaml\", cfg_name=\"train_two\")\n",
    "cfg.metric = 'auc'\n",
    "cfg.metric_mode = 'max'\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "467b975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.data import transforms_factory\n",
    "\n",
    "train_aug = transforms_factory.create_transform(\n",
    "    input_size=cfg.sz,\n",
    "    is_training=True,\n",
    "    auto_augment=f\"rand-n{cfg.n_tfms}-m{cfg.magn}\",\n",
    ")\n",
    "val_aug = transforms_factory.create_transform(\n",
    "    input_size=cfg.sz,\n",
    "    is_training=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e24ddeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = ImageDataModule(\n",
    "    task=\"classification\",\n",
    "    batch_size=cfg.bs,\n",
    "    # train\n",
    "    train_image_paths=train_image_fpaths,\n",
    "    train_targets=train_targets,\n",
    "    train_augmentations=train_aug,\n",
    "    # valid\n",
    "    val_image_paths=val_image_fpaths,\n",
    "    val_targets=val_targets,\n",
    "    val_augmentations=val_aug,\n",
    "    # test\n",
    "    test_image_paths=val_image_fpaths,\n",
    "    test_augmentations=val_aug,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d4376af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImageClassifier(\n",
    "    in_channels=3,\n",
    "    num_classes=1,\n",
    "    pretrained=cfg.pretrained,\n",
    "    cfg=cfg,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f9ca00fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl \n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    precision=cfg.precision,\n",
    "    auto_lr_find=cfg.auto_lr,\n",
    "    accumulate_grad_batches=cfg.accumulate_grad_batches,\n",
    "    auto_scale_batch_size=cfg.auto_batch_size,\n",
    "    max_epochs=cfg.epochs,\n",
    "#     logger=logger,\n",
    "#     callbacks=[checkpoint_callback, lr_callback],\n",
    "    # limit_train_batches=1,\n",
    "    # limit_val_batches=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "23744a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainerFn.FITTING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name         | Type            | Params\n",
      "-------------------------------------------------\n",
      "0 | backbone     | SwinTransformer | 194 M \n",
      "1 | head         | Sequential      | 8.3 K \n",
      "2 | train_metric | AUROC           | 0     \n",
      "3 | val_metric   | AUROC           | 0     \n",
      "-------------------------------------------------\n",
      "195 M     Trainable params\n",
      "0         Non-trainable params\n",
      "195 M     Total params\n",
      "780.015   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e9ca03aef84535987b67497bc3a453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b71f88350de0474db963c57dfacdd0bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1503b3a4d88b446098166e3350a3f642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d819b0c0856e424caeba58969fc822fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 // train metric: 0.5142, valid metric: 0.5951\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb98f1d9aa13452e81026d02f083b3ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 // train metric: 0.5427, valid metric: 0.6030\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72dad76ecc9340289e97430a4d0effc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 // train metric: 0.5674, valid metric: 0.6017\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e6f44149c33425ebd786b4a724e92ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 // train metric: 0.5947, valid metric: 0.6048\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adccff48a18f46ffbbccdb43f49ede5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 // train metric: 0.6250, valid metric: 0.6077\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "967a3a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /workspace/nbs/lightning_logs/version_93/checkpoints/epoch=5-step=737.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainerFn.PREDICTING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /workspace/nbs/lightning_logs/version_93/checkpoints/epoch=5-step=737.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "498d8a0d8bcf4db297e7a6f38470119d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 123it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = trainer.predict(model, dm.test_dataloader(), ckpt_path=\"best\")\n",
    "preds_list = [p[0] for b in preds for p in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cce9a96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "preds = np.array(preds_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6e43abf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.028442383, 0.56640625)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.min(), preds.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "99904d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(preds, bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b9a32f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision_score(val_targets, preds> 0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c050d03c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14227848101265822"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(val_targets) / len(val_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c97e4340",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(val_targets, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0e21bf8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(tpr - fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1909b10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.16015625]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def Find_Optimal_Cutoff(target, predicted):\n",
    "    \"\"\" Find the optimal probability cutoff point for a classification model related to event rate\n",
    "    Parameters\n",
    "    ----------\n",
    "    target : Matrix with dependent or target data, where rows are observations\n",
    "\n",
    "    predicted : Matrix with predicted data, where rows are observations\n",
    "\n",
    "    Returns\n",
    "    -------     \n",
    "    list type, with optimal cutoff value\n",
    "        \n",
    "    \"\"\"\n",
    "    fpr, tpr, threshold = roc_curve(target, predicted)\n",
    "    i = np.arange(len(tpr)) \n",
    "    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})\n",
    "    roc_t = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
    "\n",
    "    return list(roc_t['threshold']) \n",
    "\n",
    "\n",
    "threshold = Find_Optimal_Cutoff(val_targets, preds)\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b8967af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "850"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(preds > 0.16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "55f360b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11572266, 0.23828125, 0.06176758, ..., 0.12353516, 0.39453125,\n",
       "       0.10107422], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2325627d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
